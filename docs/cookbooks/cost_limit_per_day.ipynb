{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use `tokenator` to limit costs of your AI projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A problem that I often face : I get a cool project idea which involves using LLMs or building some kind of an AI agent. Once it's built, I want to share it with the world so that everyone can use my app and see how cool it is. \n",
    "\n",
    "But there's a problem. Running an AI project has real costs. The more people use it, the more money I need to spend powering the product. In such a case, people usually end up posting the code on github, making a video/blog or end up using a cheaper LLM and sacrificing accuracy. More substantial project integrate Auth. \n",
    "\n",
    "But not anymore!\n",
    "\n",
    "With `tokenator`, you can publish your AI project online for the world to see and set a daily cap of how much money would you like to spend on your AI project. The lucky and early access users will be able to access the project without hiccups. If people aren't able to access it today, ask them to checkout the code, your blog or comeback tomorrow!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to other `tokenator` cookbooks, we are going to be analyzing a W2 tax form and understanding how much tax this person has to pay for the year 2024.\n",
    "\n",
    "In this example, we will be doing some rate limiting using `tokenator` to control costs.\n",
    "\n",
    "Let's start with installing some dependencies. I am going to be using the openai and anthropic models to complete this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tokenator openai anthropic --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will setup 2 functions to access our model. This is done so that we don't have to initialize our openai and anthropic clients repeatedly. \n",
    "\n",
    "We will be using the structured outputs mode of openai to first get structured data out of the W2 form image and then use either openai models or anthropic models to check whether the person should get a refund."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add API Keys here\n",
    "OPENAI_API_KEY=\"api-key\"\n",
    "ANTHROPIC_API_KEY=\"api-key\"\n",
    "\n",
    "from tokenator import tokenator_openai, tokenator_anthropic\n",
    "\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "\n",
    "def call_openai_structured(system_prompt, user_prompt, image_url, model=\"gpt-4o\", execution_id=None, response_format=None):\n",
    "    client = tokenator_openai(OpenAI(api_key=OPENAI_API_KEY))\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": user_prompt},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": image_url,\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        response_format=response_format,\n",
    "        execution_id=execution_id,\n",
    "    )\n",
    "\n",
    "    return response\n",
    "\n",
    "def call_openai_unstructured(system_prompt, user_prompt, model=\"gpt-4o\"):\n",
    "    client = tokenator_openai(OpenAI(api_key=OPENAI_API_KEY))\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
    "                  {\"role\": \"user\", \"content\": user_prompt}],\n",
    "    )\n",
    "\n",
    "    return response\n",
    "\n",
    "def call_anthropic(system_prompt, user_prompt, model=\"claude-3-5-sonnet-20241022\"):\n",
    "    client = tokenator_anthropic(Anthropic(api_key=ANTHROPIC_API_KEY))\n",
    "\n",
    "    response = client.messages.create(\n",
    "        model=model,\n",
    "        system=system_prompt,\n",
    "        messages=[{\"role\": \"user\", \"content\": user_prompt}],\n",
    "        max_tokens=5000,\n",
    "    )\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we build our AI agent, let's build a cost limiter(similar to rate limiter) using `tokenator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenator import usage\n",
    "\n",
    "def cost_limiter(cost_limit_dollars) -> bool:\n",
    "    usage_last_day = usage.last_day()\n",
    "    if usage_last_day.total_cost > cost_limit_dollars:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above function, we use tokenator to get the total usage of the last day.\n",
    "Then, we use the total_cost field to compare with the cost limit set for the project.\n",
    "\n",
    "Alternatively, you can also use tokenator's other functions below to set limits hourly, weekly or monthly.\n",
    "\n",
    "```python\n",
    "usage.last_hour()\n",
    "usage.last_day()\n",
    "usage.last_week()\n",
    "usage.last_month()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build our AI agent.\n",
    "Here are the steps : \n",
    "- Before we involve any AI models, we will first use our `cost_limiter()` function to check whether ew have breached the daily cost limit. If no, we execute the agent, otherwise, we print a message and return. In a real app, you could throw an Exception which can be caught upstream.\n",
    "- Get a W2 form image\n",
    "- Pass it to OpenAI gpt 4o and get some income and tax related details\n",
    "- Use these details and ask a model whether this person should be getting a tax refund or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "def execute_agent(image_url, task1_model=\"gpt-4o\", task2_provider=\"openai\", task2_model=\"gpt-4o\", cost_limit_dollars=10):\n",
    "\n",
    "    if not cost_limiter(cost_limit_dollars):\n",
    "        print(\"Cost limit exceeded. Please try again tomorrow.\")\n",
    "        return\n",
    "    \n",
    "    # pydantic class for structured output\n",
    "    class W2Details(BaseModel):\n",
    "        name: str\n",
    "        taxation_state: str\n",
    "        income: float\n",
    "        federal_tax_paid: float\n",
    "        state_tax_paid: float\n",
    "        social_security_tax_paid: float\n",
    "        medicare_tax_paid: float\n",
    "\n",
    "    user_prompt = f\"Extract the following details from the W2 form image : {image_url}\"\n",
    "\n",
    "    system_prompt = \"You are an expert at extracting details from W2 forms. You are given an image of a W2 form and you need to extract the fields required in the output\"\n",
    "\n",
    "    # 1st LLM call\n",
    "    response = call_openai_structured(\n",
    "        system_prompt=system_prompt, \n",
    "        user_prompt=user_prompt, \n",
    "        image_url=image_url, \n",
    "        model=task1_model, \n",
    "        response_format=W2Details\n",
    "    )\n",
    "\n",
    "    print(\"Extracted details from W2 form : \")\n",
    "    print(response.choices[0].message.content)\n",
    "\n",
    "\n",
    "    # ------------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Now, we will use the extracted details to ask a model whether this person should be getting a tax refund or not\n",
    "    user_prompt = f\"Based on the following details, determine if this person should be getting a tax refund or not : {response.choices[0].message.content}\"\n",
    "\n",
    "    system_prompt = \"You are an expert at determining whether a person should be getting a tax refund or not. You are given a set of details and you need to determine if this person should be getting a tax refund or not. Assume no deductions or credits are applied to the income. Reply concisely.\"\n",
    "\n",
    "    # 2nd LLM call\n",
    "    if task2_provider == \"openai\":\n",
    "        response = call_openai_unstructured(\n",
    "            system_prompt, \n",
    "            user_prompt, \n",
    "            model=task2_model\n",
    "        )\n",
    "        print(\"Refund status : \")\n",
    "        print(response.choices[0].message.content)\n",
    "\n",
    "    elif task2_provider == \"anthropic\":\n",
    "        response = call_anthropic(\n",
    "            system_prompt, \n",
    "            user_prompt, \n",
    "            model=task2_model\n",
    "        )\n",
    "        print(\"Refund status : \")\n",
    "        print(response.content[0].text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run our agent in a loop to see if our rate limiting works or not.\n",
    "Just to simulate a cost limiting case, we will keep an artificially low cost limit of 1 cent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running agent 1 of 10\n",
      "Extracted details from W2 form : \n",
      "{\"name\":\"Abby L Smith\",\"taxation_state\":\"OH\",\"income\":50000.00,\"federal_tax_paid\":4092.00,\"state_tax_paid\":1040.88,\"social_security_tax_paid\":3100.00,\"medicare_tax_paid\":725.00}\n",
      "Refund status : \n",
      "To determine if Abby L Smith should get a tax refund, let's evaluate the taxes:\n",
      "\n",
      "1. **Federal Tax**: \n",
      "    - 2023 Federal Income Tax Rates for a single filer:\n",
      "      - 10% on income up to $11,000\n",
      "      - 12% on income from $11,001 to $44,725\n",
      "      - 22% on income from $44,726 to $95,375\n",
      "\n",
      "   Calculating Abby's federal tax:\n",
      "   - 10% of $11,000 = $1,100\n",
      "   - 12% of ($44,725 - $11,001) = $4,047\n",
      "   - 22% of ($50,000 - $44,725) = $1,159.50\n",
      "   - Total federal tax: $1,100 + $4,047 + $1,159.50 = $6,306.50\n",
      "\n",
      "   Abby paid $4,092.00, so she overpaid by $6,306.50 - $4,092.00 = $2,214.50.\n",
      "\n",
      "2. **State Tax**: \n",
      "   - Ohio uses a progressive tax system, but without specific brackets/rates, assume Abby's payment aligns roughly with her liability.\n",
      "\n",
      "Abby L Smith should be getting a federal tax refund due to overpayment of federal taxes by $2,214.50. State tax is assumed to be aligned with what she should have paid.\n",
      "--------------------------------\n",
      "Running agent 2 of 10\n",
      "Cost limit exceeded. Please try again tomorrow.\n",
      "--------------------------------\n",
      "Running agent 3 of 10\n",
      "Cost limit exceeded. Please try again tomorrow.\n",
      "--------------------------------\n",
      "Running agent 4 of 10\n",
      "Cost limit exceeded. Please try again tomorrow.\n",
      "--------------------------------\n",
      "Running agent 5 of 10\n",
      "Cost limit exceeded. Please try again tomorrow.\n",
      "--------------------------------\n",
      "Running agent 6 of 10\n",
      "Cost limit exceeded. Please try again tomorrow.\n",
      "--------------------------------\n",
      "Running agent 7 of 10\n",
      "Cost limit exceeded. Please try again tomorrow.\n",
      "--------------------------------\n",
      "Running agent 8 of 10\n",
      "Cost limit exceeded. Please try again tomorrow.\n",
      "--------------------------------\n",
      "Running agent 9 of 10\n",
      "Cost limit exceeded. Please try again tomorrow.\n",
      "--------------------------------\n",
      "Running agent 10 of 10\n",
      "Cost limit exceeded. Please try again tomorrow.\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "image_url = \"https://www.patriotsoftware.com/wp-content/uploads/2024/03/2024-Form-W-2-1.png\"\n",
    "\n",
    "for i in range(10):\n",
    "    print(f\"Running agent {i+1} of 10\")\n",
    "    execute_agent(image_url=image_url, cost_limit_dollars=0.05)\n",
    "    print(\"--------------------------------\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
