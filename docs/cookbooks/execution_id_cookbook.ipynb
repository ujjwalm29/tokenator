{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use `execution_id` in tokenator to track usage across a set of executions\n",
    "\n",
    "Most complex LLM workflows and AI agents use multiple LLM calls, possibly multiple LLM API providers, to achieve a task. With tokenator's `execution_id` field, one can easily track and monitor token usage and cost of an AI agent completing a task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we are going to be analyzing a W2 tax form and understanding how much tax this person has to pay for the year 2024. Using, tokenator, we will run all kinds of analyses to build the most cost effective AI agent.\n",
    "\n",
    "Let's start with installing some dependencies. I am going to be using the openai and anthropic models to complete this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 24.3.1 is available.\n",
      "You should consider upgrading via the '/Users/ujjwal/.pyenv/versions/3.10.0/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install e /Users/ujjwal/xfic/token-usage/ openai anthropic --quiet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will setup 2 functions to access our model. This is done so that we don't have to initialize our openai and anthropic clients repeatedly. Also, we will be using structured outputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add API Keys here\n",
    "OPENAI_API_KEY=\"openai-key\"\n",
    "ANTHROPIC_API_KEY=\"anthropic-key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenator import tokenator_openai, tokenator_anthropic\n",
    "\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "\n",
    "def call_openai_structured(system_prompt, user_prompt, image_url, model=\"gpt-4o\", execution_id=None, response_format=None):\n",
    "    client = tokenator_openai(OpenAI(api_key=OPENAI_API_KEY))\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": user_prompt},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": image_url,\n",
    "                    },\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    response = client.beta.chat.completions.parse(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        response_format=response_format,\n",
    "        execution_id=execution_id,\n",
    "    )\n",
    "\n",
    "    return response\n",
    "\n",
    "def call_openai_unstructured(system_prompt, user_prompt, model=\"gpt-4o\", execution_id=None):\n",
    "    client = tokenator_openai(OpenAI(api_key=OPENAI_API_KEY))\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"system\", \"content\": system_prompt},\n",
    "                  {\"role\": \"user\", \"content\": user_prompt}],\n",
    "        execution_id=execution_id,\n",
    "    )\n",
    "\n",
    "    return response\n",
    "\n",
    "def call_anthropic(system_prompt, user_prompt, model=\"claude-3-5-sonnet-20241022\", execution_id=None):\n",
    "    client = tokenator_anthropic(Anthropic(api_key=ANTHROPIC_API_KEY))\n",
    "\n",
    "    response = client.messages.create(\n",
    "        model=model,\n",
    "        system=system_prompt,\n",
    "        messages=[{\"role\": \"user\", \"content\": user_prompt}],\n",
    "        execution_id=execution_id,\n",
    "        max_tokens=5000,\n",
    "    )\n",
    "\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build our AI agent.\n",
    "Here are the steps : \n",
    "- Get a W2 form image\n",
    "- Pass it to OpenAI gpt 4o and get some income and tax related details\n",
    "- Use these details and ask a model whether this person should be getting a tax refund or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "def execute_agent(image_url, execution_id, task1_model=\"gpt-4o\", task2_provider=\"openai\", task2_model=\"gpt-4o\"):   \n",
    "\n",
    "    # pydantic class for structured output\n",
    "    class W2Details(BaseModel):\n",
    "        name: str\n",
    "        taxation_state: str\n",
    "        income: float\n",
    "        federal_tax_paid: float\n",
    "        state_tax_paid: float\n",
    "        social_security_tax_paid: float\n",
    "        medicare_tax_paid: float\n",
    "\n",
    "    user_prompt = f\"Extract the following details from the W2 form image : {image_url}\"\n",
    "\n",
    "    system_prompt = \"You are an expert at extracting details from W2 forms. You are given an image of a W2 form and you need to extract the fields required in the output\"\n",
    "\n",
    "    # 1st LLM call\n",
    "    response = call_openai_structured(\n",
    "        system_prompt=system_prompt, \n",
    "        user_prompt=user_prompt, \n",
    "        image_url=image_url, \n",
    "        model=task1_model, \n",
    "        response_format=W2Details, \n",
    "        execution_id=execution_id\n",
    "    )\n",
    "\n",
    "    print(\"Extracted details from W2 form : \")\n",
    "    print(response.choices[0].message.content)\n",
    "\n",
    "\n",
    "    # ------------------------------------------------------------------------------------------------\n",
    "\n",
    "    # Now, we will use the extracted details to ask a model whether this person should be getting a tax refund or not\n",
    "    user_prompt = f\"Based on the following details, determine if this person should be getting a tax refund or not : {response.choices[0].message.content}\"\n",
    "\n",
    "    system_prompt = \"You are an expert at determining whether a person should be getting a tax refund or not. You are given a set of details and you need to determine if this person should be getting a tax refund or not. Assume no deductions or credits are applied to the income\"\n",
    "\n",
    "    if task2_provider == \"openai\":\n",
    "        response = call_openai_unstructured(\n",
    "            system_prompt, \n",
    "            user_prompt, \n",
    "            model=task2_model,\n",
    "            execution_id=execution_id\n",
    "        )\n",
    "        print(\"Refund status : \")\n",
    "        print(response.choices[0].message.content)\n",
    "\n",
    "    elif task2_provider == \"anthropic\":\n",
    "        response = call_anthropic(\n",
    "            system_prompt, \n",
    "            user_prompt, \n",
    "            model=task2_model,\n",
    "            execution_id=execution_id\n",
    "        )\n",
    "        print(\"Refund status : \")\n",
    "        print(response.content[0].text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our AI agent is all set!\n",
    "\n",
    "The extra parameters such as task1_model, task2_provider, task2_model are hepful in experimenting with different models. \n",
    "\n",
    "Let's run the agent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get image\n",
    "image_url = \"https://www.patriotsoftware.com/wp-content/uploads/2024/03/2024-Form-W-2-1.png\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try with gpt-4o model for all the LLM calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6860675a-f506-4b48-8699-9c3c3f57f375\n",
      "Extracted details from W2 form : \n",
      "{\"name\":\"Abby L Smith\",\"taxation_state\":\"OH\",\"income\":50000,\"federal_tax_paid\":4092,\"state_tax_paid\":1040.88,\"social_security_tax_paid\":3100,\"medicare_tax_paid\":725}\n",
      "Refund status : \n",
      "To determine if Abby L Smith should be getting a tax refund, we need to calculate her correctly owed taxes based on her given details and compare them with the taxes she has already paid.\n",
      "\n",
      "1. **Federal Taxes:**\n",
      "   - For 2023, the federal income tax brackets for a single filer are:\n",
      "     - 10% on income up to $11,000\n",
      "     - 12% on income from $11,001 to $44,725\n",
      "     - 22% on income from $44,726 to $95,375\n",
      "   - Calculate her federal tax liability:\n",
      "     - Tax on first $11,000 = $1,100 (10%)\n",
      "     - Tax on income between $11,001 and $44,725 = ($44,725 - $11,000) * 12% = $4,041\n",
      "     - Tax on income between $44,726 and $50,000 = ($50,000 - $44,725) * 22% = $1,159.50\n",
      "     - Total federal tax owed = $1,100 + $4,041 + $1,159.50 = $6,300.50\n",
      "   - Federal tax paid = $4,092\n",
      "   - Federal tax difference (refund or owed) = $4,092 - $6,300.50 = -$2,208.50 (she owes $2,208.50, thus no refund from federal taxes)\n",
      "\n",
      "2. **State Taxes:**\n",
      "   - Ohio has a progressive tax system, with 2023 rates approximately as follows:\n",
      "     - 0% on income up to $26,050\n",
      "     - 2.765% on income over $26,050 up to $46,100\n",
      "     - 3.226% on income over $46,100\n",
      "   - Calculate her Ohio state tax liability:\n",
      "     - Tax on first $26,050 = $0\n",
      "     - Tax on income between $26,051 and $46,100 = ($46,100 - $26,050) * 2.765% = $553.10\n",
      "     - Tax on income between $46,101 and $50,000 = ($50,000 - $46,100) * 3.226% = $125.87\n",
      "     - Total Ohio state tax owed = $553.10 + $125.87 = $678.97\n",
      "   - State tax paid = $1,040.88\n",
      "   - State tax difference (refund or owed) = $1,040.88 - $678.97 = $361.91 (refund from state taxes)\n",
      "\n",
      "**Conclusion:**\n",
      "\n",
      "Abby will receive a state tax refund of $361.91, but she owes $2,208.50 in federal taxes. Overall, she will not be receiving a net tax refund due to the amount owed to the federal government.\n"
     ]
    }
   ],
   "source": [
    "# execute agent\n",
    "import uuid\n",
    "\n",
    "tokenator_execution_id = str(uuid.uuid4())\n",
    "print(tokenator_execution_id)\n",
    "\n",
    "execute_agent(image_url, tokenator_execution_id, task1_model=\"gpt-4o\", task2_provider=\"openai\", task2_model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results seem interesting. But let's try out Anthropics claude Sonnet 3.5 to check if we can get a better explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d3c539ba-bc71-46a7-ad6b-88483c3fd294\n",
      "Extracted details from W2 form : \n",
      "{\"name\":\"Abby L Smith\",\"taxation_state\":\"OH\",\"income\":50000,\"federal_tax_paid\":4092,\"state_tax_paid\":1040.88,\"social_security_tax_paid\":3100,\"medicare_tax_paid\":725}\n",
      "Refund status : \n",
      "I'll help analyze if Abby L Smith should receive a tax refund. Let's break this down:\n",
      "\n",
      "1. Federal Tax:\n",
      "- Income: $50,000\n",
      "- For 2023 tax brackets, on $50,000:\n",
      "  * Standard federal tax liability would be approximately $5,553\n",
      "  * Actual federal tax paid: $4,092\n",
      "  * UNDERPAID by about $1,461\n",
      "\n",
      "2. State Tax (Ohio):\n",
      "- Ohio state tax on $50,000 would be approximately $1,030\n",
      "- Actually paid: $1,040.88\n",
      "- OVERPAID by about $10.88\n",
      "\n",
      "3. Social Security Tax:\n",
      "- Required rate is 6.2% of income\n",
      "- On $50,000 should be: $3,100\n",
      "- Actually paid: $3,100\n",
      "- CORRECT amount paid\n",
      "\n",
      "4. Medicare Tax:\n",
      "- Required rate is 1.45% of income\n",
      "- On $50,000 should be: $725\n",
      "- Actually paid: $725\n",
      "- CORRECT amount paid\n",
      "\n",
      "Conclusion: NO, Abby should NOT expect a tax refund. She has significantly UNDERPAID her federal taxes by about $1,461. While she slightly overpaid state taxes by about $11, the federal underpayment is much larger and she will likely need to pay additional taxes when filing her return. She paid the correct amounts for Social Security and Medicare taxes.\n"
     ]
    }
   ],
   "source": [
    "# execute agent\n",
    "import uuid\n",
    "\n",
    "tokenator_execution_id = str(uuid.uuid4())\n",
    "print(tokenator_execution_id)\n",
    "\n",
    "execute_agent(image_url, tokenator_execution_id, task1_model=\"gpt-4o\", task2_provider=\"anthropic\", task2_model=\"claude-3-5-sonnet-20241022\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmmm interesting, claude sonnet seems to think the taxes are significantly underpaid.\n",
    "\n",
    "You know what, let's throw a mountain of compute on this problem. Let's use openai o1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99d9cfd9-d7ca-4057-9784-5acd1bff26af\n",
      "Extracted details from W2 form : \n",
      "{\"name\":\"Abby L Smith\",\"taxation_state\":\"OH\",\"income\":50000.0,\"federal_tax_paid\":4092.0,\"state_tax_paid\":1040.88,\"social_security_tax_paid\":3100.0,\"medicare_tax_paid\":725.0}\n",
      "Refund status : \n",
      "Below is a very basic breakdown (assuming 2023 rates and no deductions/credits at all) to illustrate why Abby would not be getting a refund.\n",
      "\n",
      "────────────────────────────────────\n",
      "1) FEDERAL TAX (SINGLE FILER, 2023)\n",
      "────────────────────────────────────\n",
      "• First $11,000 at 10%  → $1,100  \n",
      "• Next $33,725 at 12%   → $4,047  (that is $44,725 – $11,000 = $33,725 × 12%)  \n",
      "• Remaining $5,275 at 22% → $1,160.50 (that is $50,000 – $44,725 = $5,275 × 22%)  \n",
      "\n",
      "Approx. Federal Tax Liability = $1,100 + $4,047 + $1,160.50 ≈ $6,307.50  \n",
      "\n",
      "Federal Tax Paid = $4,092.00  \n",
      "→ She is underpaid by about $6,307.50 – $4,092.00 = $2,215.50  \n",
      "\n",
      "────────────────────────────────────────────\n",
      "2) OHIO STATE TAX (2023 BRACKETS, NO CREDITS)\n",
      "────────────────────────────────────────────\n",
      "For $50,000 taxable income (no deductions):\n",
      "• $44,444 threshold bracket => $852.83 + 3.75% of ($50,000 – $44,444)  \n",
      "• 3.75% of $5,556 = $208.35  \n",
      "State Tax Liability ≈ $852.83 + $208.35 = $1,061.18  \n",
      "\n",
      "State Tax Paid = $1,040.88  \n",
      "→ She is underpaid by about $1,061.18 – $1,040.88 = $20.30  \n",
      "\n",
      "────────────────────────────────────────\n",
      "3) SOCIAL SECURITY & MEDICARE\n",
      "────────────────────────────────────────\n",
      "Those are “fixed” withholding taxes (no typical refunds unless over the wage limit or special circumstances). Abby paid $3,100 (Social Security) and $725 (Medicare), which are normal amounts for $50,000 in wage income.\n",
      "\n",
      "────────────────────────────────────\n",
      "4) NET RESULT\n",
      "────────────────────────────────────\n",
      "Abby’s total tax paid is less than her total tax liability (both federal and state). Therefore, she would not be getting a refund—instead, she would likely owe additional taxes.\n"
     ]
    }
   ],
   "source": [
    "# execute agent\n",
    "import uuid\n",
    "\n",
    "tokenator_execution_id = str(uuid.uuid4())\n",
    "print(tokenator_execution_id)\n",
    "\n",
    "execute_agent(image_url, tokenator_execution_id, task1_model=\"gpt-4o\", task2_provider=\"openai\", task2_model=\"o1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! `o1`, with it's extra compute, agrees with claude sonnet and thinks that Abby will have to pay additional taxes.\n",
    "Now let's look at the cost of each execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage with gpt-4o for both tasks : \n",
      "{\n",
      "  \"total_cost\": 0.009503,\n",
      "  \"total_tokens\": 1860,\n",
      "  \"prompt_tokens\": 1213,\n",
      "  \"completion_tokens\": 647,\n",
      "  \"prompt_tokens_details\": null,\n",
      "  \"completion_tokens_details\": null,\n",
      "  \"providers\": [\n",
      "    {\n",
      "      \"total_cost\": 0.009503,\n",
      "      \"total_tokens\": 1860,\n",
      "      \"prompt_tokens\": 1213,\n",
      "      \"completion_tokens\": 647,\n",
      "      \"prompt_tokens_details\": null,\n",
      "      \"completion_tokens_details\": null,\n",
      "      \"provider\": \"openai\",\n",
      "      \"models\": [\n",
      "        {\n",
      "          \"total_cost\": 0.009503,\n",
      "          \"total_tokens\": 1860,\n",
      "          \"prompt_tokens\": 1213,\n",
      "          \"completion_tokens\": 647,\n",
      "          \"prompt_tokens_details\": null,\n",
      "          \"completion_tokens_details\": null,\n",
      "          \"model\": \"gpt-4o-2024-08-06\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Usage with gpt-4o for task 1 and claude sonnet for task 2 : \n",
      "{\n",
      "  \"total_cost\": 0.008446,\n",
      "  \"total_tokens\": 1594,\n",
      "  \"prompt_tokens\": 1222,\n",
      "  \"completion_tokens\": 372,\n",
      "  \"prompt_tokens_details\": null,\n",
      "  \"completion_tokens_details\": null,\n",
      "  \"providers\": [\n",
      "    {\n",
      "      \"total_cost\": 0.00322,\n",
      "      \"total_tokens\": 1132,\n",
      "      \"prompt_tokens\": 1080,\n",
      "      \"completion_tokens\": 52,\n",
      "      \"prompt_tokens_details\": null,\n",
      "      \"completion_tokens_details\": null,\n",
      "      \"provider\": \"openai\",\n",
      "      \"models\": [\n",
      "        {\n",
      "          \"total_cost\": 0.00322,\n",
      "          \"total_tokens\": 1132,\n",
      "          \"prompt_tokens\": 1080,\n",
      "          \"completion_tokens\": 52,\n",
      "          \"prompt_tokens_details\": null,\n",
      "          \"completion_tokens_details\": null,\n",
      "          \"model\": \"gpt-4o-2024-08-06\"\n",
      "        }\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"total_cost\": 0.005226,\n",
      "      \"total_tokens\": 462,\n",
      "      \"prompt_tokens\": 142,\n",
      "      \"completion_tokens\": 320,\n",
      "      \"prompt_tokens_details\": null,\n",
      "      \"completion_tokens_details\": null,\n",
      "      \"provider\": \"anthropic\",\n",
      "      \"models\": [\n",
      "        {\n",
      "          \"total_cost\": 0.005226,\n",
      "          \"total_tokens\": 462,\n",
      "          \"prompt_tokens\": 142,\n",
      "          \"completion_tokens\": 320,\n",
      "          \"prompt_tokens_details\": null,\n",
      "          \"completion_tokens_details\": null,\n",
      "          \"model\": \"claude-3-5-sonnet-20241022\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "------------------------------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Usage with gpt-4o for task 1 and o1 for task 2 : \n",
      "{\n",
      "  \"total_cost\": 0.10794,\n",
      "  \"total_tokens\": 2989,\n",
      "  \"prompt_tokens\": 1220,\n",
      "  \"completion_tokens\": 1769,\n",
      "  \"prompt_tokens_details\": null,\n",
      "  \"completion_tokens_details\": null,\n",
      "  \"providers\": [\n",
      "    {\n",
      "      \"total_cost\": 0.10794,\n",
      "      \"total_tokens\": 2989,\n",
      "      \"prompt_tokens\": 1220,\n",
      "      \"completion_tokens\": 1769,\n",
      "      \"prompt_tokens_details\": null,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"reasoning_tokens\": 1216,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"provider\": \"openai\",\n",
      "      \"models\": [\n",
      "        {\n",
      "          \"total_cost\": 0.0033,\n",
      "          \"total_tokens\": 1140,\n",
      "          \"prompt_tokens\": 1080,\n",
      "          \"completion_tokens\": 60,\n",
      "          \"prompt_tokens_details\": null,\n",
      "          \"completion_tokens_details\": null,\n",
      "          \"model\": \"gpt-4o-2024-08-06\"\n",
      "        },\n",
      "        {\n",
      "          \"total_cost\": 0.10464,\n",
      "          \"total_tokens\": 1849,\n",
      "          \"prompt_tokens\": 140,\n",
      "          \"completion_tokens\": 1709,\n",
      "          \"prompt_tokens_details\": null,\n",
      "          \"completion_tokens_details\": {\n",
      "            \"reasoning_tokens\": 1216,\n",
      "            \"audio_tokens\": 0,\n",
      "            \"accepted_prediction_tokens\": 0,\n",
      "            \"rejected_prediction_tokens\": 0\n",
      "          },\n",
      "          \"model\": \"o1-2024-12-17\"\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from tokenator import usage\n",
    "\n",
    "print(\"Usage with gpt-4o for both tasks : \")\n",
    "print(usage.for_execution(\"6860675a-f506-4b48-8699-9c3c3f57f375\").model_dump_json(indent=2))\n",
    "\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\n\\nUsage with gpt-4o for task 1 and claude sonnet for task 2 : \")\n",
    "print(usage.for_execution(\"d3c539ba-bc71-46a7-ad6b-88483c3fd294\").model_dump_json(indent=2))\n",
    "\n",
    "print(\"------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\n\\nUsage with gpt-4o for task 1 and o1 for task 2 : \")\n",
    "print(usage.for_execution(\"99d9cfd9-d7ca-4057-9784-5acd1bff26af\").model_dump_json(indent=2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the help of tokenator, we are clearly able to determine what the token usage and cost related to each model is. We can see that even though openai `o1` gave us maybe the clearest formatted answer, it is clearly way more expensive than claude sonnet 3.5 and gpt-4o. Depending on your specific task, you should use evaluations to determine the accuracy of each model on your task. Then, using tokenator's cost analysis, choose the correct model for your task."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tokenator-zqTvcd5M-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
